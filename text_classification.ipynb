{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ic4_occAAiAT"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "ioaprt5q5US7"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "yCl0eTNH5RS3"
   },
   "outputs": [],
   "source": [
    "#@title MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.executable)\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# Basic text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKY4XMc9o8iB"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "This tutorial demonstrates text classification starting from plain text files stored on disk. You'll train a binary classifier to perform sentiment analysis on an IMDB dataset. At the end of the notebook, there is an exercise for you to try, in which you'll train a multiclass classifier to predict the tag for a programming question on Stack Overflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TEnXCeDXHWkJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tf-nightly in /home/klemen/.local/lib/python3.7/site-packages (2.4.0.dev20200816)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (1.12)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (0.9.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tf-nightly) (1.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (3.3.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (1.31.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (0.35.1)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (1.18.5)\n",
      "Requirement already satisfied: tf-estimator-nightly in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (2.4.0.dev2020081701)\n",
      "Requirement already satisfied: tb-nightly<3.0.0a0,>=2.4.0a0 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (2.4.0a20200816)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (3.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (0.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/klemen/.local/lib/python3.7/site-packages (from tf-nightly) (1.1.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/klemen/.local/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.21.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/klemen/.local/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/klemen/.local/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/klemen/.local/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (49.6.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/klemen/.local/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.20.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/klemen/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/klemen/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/klemen/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/klemen/.local/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/klemen/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/klemen/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8RZOuS9LWQvv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-tTFS04dChr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0-dev20200816\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NBTI1bi8qdFV"
   },
   "source": [
    "## Sentiment analysis\n",
    "\n",
    "This notebook trains a sentiment analysis model to classify movie reviews as *positive* or *negative*, based on the text of the review. This is an example of *binary*—or two-class—classification, an important and widely applicable kind of machine learning problem.\n",
    "\n",
    "You'll use the [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/) that contains the text of 50,000 movie reviews from the [Internet Movie Database](https://www.imdb.com/). These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are *balanced*, meaning they contain an equal number of positive and negative reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAsKG535pHep"
   },
   "source": [
    "### Download and explore the IMDB dataset\n",
    "\n",
    "Let's download and extract the dataset, then explore the directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7ZYnuajVlFN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84131840/84125825 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "#dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url,\n",
    "#                                    untar=True, cache_dir='.',\n",
    "#                                    cache_subdir='')\n",
    "\n",
    "#dataset_dir = os.path.join(os.path.dirname(dataset), 'aiData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "355CfOvsV1pl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0900000190c5b8d7.pdf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = os.path.join('/tmp', 'classify')\n",
    "os.listdir(dataset_dir)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ASND15oXpF1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'398'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "os.listdir(train_dir)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysMNMI1CWDFD"
   },
   "source": [
    "The `aclImdb/train/pos` and `aclImdb/train/neg` directories contain many text files, each of which is a single movie review. Let's take a look at one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7g8hFvzWLIZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{GE Tolekomsioveni UL\n",
      "\n",
      "0941020200731 09099\n",
      "5 1607886 3397894\n",
      " Pegoč iba o naročniškem razmerju ID-naročila SPP\n",
      "\n",
      "za uporabo elektronskih komuni kaci ijskih storitev\n",
      "\n",
      "Stevilka pogodbe: 31072020/1/1807886\n",
      "ki jo dogovorita in skleneta Telekom Slovenije, d.d., Cigaletova 15, 1000 Ljubljana (v nadaljevanju: Telekom Slovenije) in naročnik:\n",
      "\n",
      "MIHELČIČ JAKA\n",
      "\n",
      "priimek in ime/naziv pravne osebe\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "    \n",
      "\n",
      " \n",
      "\n",
      "KAMNICA 46\n",
      "\n",
      "naslov stalnega bivališča/sedež pravne osebe\n",
      "\n",
      "1262 DOL PRI LJUBLJANI\n",
      "\n",
      "poštna številka in ime pošte\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "30239796 LJ da ne\n",
      "davéna Stevilka davéni zavezanec\n",
      "\n",
      "L] Zenski moški [ | ne želim podati podatkov o spolu 8.9.1988\n",
      "spol\" rojstni datum\"\n",
      "\n",
      "Osebna Izkaznica\n",
      "\n",
      "vrsta osebnega dokumenta\"\n",
      "\n",
      " \n",
      "\n",
      "38641206415\n",
      "\n",
      "kontaktni GSM naročnika\"\n",
      "\n",
      "\" Podatki, ki so označeni z zvezdico, so neobvezni.\n",
      "\n",
      "Uvodne določbe\n",
      "\n",
      "1. člen\n",
      "\n",
      "Predmet pogodbe ter druge pravice in obveznosti iz pogodbenega razmerja, ki se nanašajo na sklenitev naročniških razmerij za posamezne\n",
      "elektronske komunikacijske storitve Telekoma Slovenije (v nadaljevanju: storitve Telekoma Slovenije), pogodbeni stranki določita v posameznih\n",
      "dodatkih k tej pogodbi.\n",
      "\n",
      "Pogodbeni stranki soglašata, da vsak dodatek k tej pogodbi predstavlja obvezen in neločljiv sestavni del te pogodbe.\n",
      "\n",
      "Če se določbe v dodatku razlikujejo od določb v tej pogodbi, veljajo določbe iz dodatka.\n",
      "\n",
      "Soglasja\n",
      "2. člen\n",
      "\n",
      "Naročnik potrjuje, da je v celoti seznanjen in soglaša s Splošnimi pogoji uporabe elektronskih komunikacijskih storitev družbe Telekoma\n",
      "Slovenije, d.d. (SPU), ki so sestavni del te pogodbe.\n",
      "\n",
      "S sklenitvijo posameznega dodatka k tej pogodbi naročnik tudi potrjuje, da je v celoti seznanjen in soglaša s posebnimi pogoji (PP), prodajno\n",
      "ponudbo, navodili in cenikom, ki veljajo za posamezno storitev Telekoma Slovenije, za katero sklepa dodatek k tej pogodbi.\n",
      "\n",
      "SPU, PP, prodajna ponudba, cenik in navodila so dostopni na spletnem mestu Telekoma Slovenije: http://www.telekom.si ter na prodajnih\n",
      "mestih Telekoma Slovenije že pred sklenitvijo naročniškega razmerja za posamezno storitev.\n",
      "\n",
      "Naročnik soglaša, da se mu SPU posredujejo ob podpisu pogodbe:\n",
      "\n",
      "LI] v elektronski obliki na elektronski naslov:\n",
      "\n",
      "L] v papirni obliki\n",
      "\n",
      "3. člen\n",
      "Naročnik soglaša, da obvestila o spremembi pogojev iz naročniške pogodbe prejme na naslednji način:\n",
      "\n",
      "[ | s sporočilom SMS na mobilno številko:\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "LL] na elektronski naslov:\n",
      "[X] pisno na naslov naročnika: KAMNICA 46, 1262 DOL PRI LJUBLJANI\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Naročnik s podpisom pogodbe in sestavnih delov te pogodbe naroča storitve oziroma blago Telekoma Slovenije z vsemi pravicami in\n",
      "obveznostmi, ki izhajajo iz te pogodbe, SPU in PP za posamezno storitev. Naročniško razmerje mora uporabljati izključno za namene, določene\n",
      "s to pogodbo, SPU in PP za posamezno storitev kot končni uporabnik.\n",
      "\n",
      "4. člen\n",
      "\n",
      "Naročnik izjavlja, da so podatki, ki jih je/bo navedel v pogodbi in v sestavnih delih te pogodbe, točni in resnični. Soglaša, da lahko Telekom\n",
      "Slovenije podatke iz te pogodbe in iz sestavnih delov te pogodbe zbira, obdeluje in preverja za namen izvajanja te pogodbe ter lahko z\n",
      "namenom nemotenega izvajanja naročniške pogodbe kadarkoli in od kateregakoli organa, institucije, delodajalca, banke ali drugega upravljavca\n",
      "osebnih podatkov pridobi zahtevane podatke.\n",
      "\n",
      "Veljavnost pogodbe\n",
      "\n",
      "5. člen\n",
      "Ta pogodba prične veljati z dnem podpisa obeh strank.\n",
      "\n",
      "6. člen\n",
      "Pogodba je sklenjena za nedoločen čas.\n",
      "\n",
      "Stran 1 od 2\n",
      "Telekom Slovenije, d.d., Cigaletova 15, 1000 Ljubljana, tel.: 4386 1 234 10 00, www.telekom.si\n",
      "\n",
      "Vložna številka: 1/248624/00, Okrožno sodišče v Ljubljani, Osnovni kapital: 272.720.664,33 EUR, Matična številka 5014018, Identifikacijska številka za DDV: SI98511734\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6.\n",
      "49. TelekomSlovenije\n",
      "de\n",
      "\n",
      "7. člen\n",
      "\n",
      "Prenehanje posameznega naročniškega razmerja za določeno storitev Telekoma Slovenije, opredeljeno v posameznemu dodatku k tej pogodbi,\n",
      "ne vpliva na pravno veljavnost preostalih naročniških razmerij za storitev Telekoma Slovenije, opredeljenih v dodatkih k tej pogodbi; ravno tako\n",
      "ne vpliva na veljavnost predmetne pogodbe.\n",
      "\n",
      "V primeru prenehanja vseh naročniških razmerij za posamezne storitve Telekoma Slovenije, določenih v posameznih dodatkih k tej pogodbi, se\n",
      "šteje, da s tem preneha veljati tudi predmetna pogodba.\n",
      "\n",
      "Končne določbe\n",
      "\n",
      "8. člen\n",
      "Pogodbeni stranki člen soglašata, da bosta vse spore, nastale iz te pogodbe, reševali sporazumno. V primeru, da se pogodbeni stranki ne bosta\n",
      "mogli sporazumeti, bo spore reševalo pristojno sodišče glede na naslov naročnika.\n",
      "\n",
      "9. člen\n",
      "Ta pogodba je napisana v dveh (2) enakih izvodih, od katerih prejme vsaka pogodbena stranka po en (1) izvod.\n",
      "\n",
      "Podpisal: Telekom Slovenije, d.d\n",
      "\n",
      "Kraj podpisa: LJUBLJANA\n",
      "\n",
      "Podpisano dne: 2020-07-31, 17:54:02\n",
      "Razlog podpisa: ePero elektronski podpis\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Telekom Slovenije d.d., po pooblastilu uprave\n",
      "\n",
      "eS\n",
      "\n",
      "podpis naročnika/zastopnika pravne osebe\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Potrjujem, da sem preveril vse podatke, ki so navedeni v tej pogodbi, in jamčim, da so točni in resnični. GO 3.1/0001.6 (17. 7. 2019)\n",
      "PULKO EDITA 2683 LJUBLJANA 31.7.2020\n",
      "izpis imena zaposlenega Sifra prodajalca šifra prodajnega mesta kraj datum\n",
      "Stran 2 od 2\n",
      "\n",
      "Telekom Slovenije, d.d., Cigaletova 15, 1000 Ljubljana, tel.: 4386 1 234 10 00, www.telekom.si\n",
      "\n",
      "Vložna številka: 1/248624/00, Okrožno sodišče v Ljubljani, Osnovni kapital: 272.720.664,33 EUR, Matična številka 5014018, Identifikacijska številka za DDV: SI98511734\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_file = os.path.join(train_dir, '398/0900000191555462.pdf.txt')\n",
    "with open(sample_file) as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mk20TEm6ZRFP"
   },
   "source": [
    "### Load the dataset\n",
    "\n",
    "Next, you will load the data off disk and prepare it into a format suitable for training. To do so, you will use the helpful [text_dataset_from_directory](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text_dataset_from_directory) utility, which expects a directory structure as follows.\n",
    "\n",
    "```\n",
    "main_directory/\n",
    "...class_a/\n",
    "......a_text_1.txt\n",
    "......a_text_2.txt\n",
    "...class_b/\n",
    "......b_text_1.txt\n",
    "......b_text_2.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQauv38Lnok3"
   },
   "source": [
    "To prepare a dataset for binary classification, you will need two folders on disk, corresponding to `class_a` and `class_b`. These will be the positive and negative movie reviews, which can be found in  `aclImdb/train/pos` and `aclImdb/train/neg`. As the IMDB dataset contains additional folders, you will remove them before using this utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VhejsClzaWfl"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/classify/train/unsup'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c3019530ae67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mremove_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unsup'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/classify/train/unsup'"
     ]
    }
   ],
   "source": [
    "remove_dir = os.path.join(train_dir, 'unsup')\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "95kkUdRoaeMw"
   },
   "source": [
    "Next, you will use the `text_dataset_from_directory` utility to create a labeled `tf.data.Dataset`. [tf.data](https://www.tensorflow.org/guide/data) is a powerful collection of tools for working with data. \n",
    "\n",
    "When running a machine learning experiment, it is a best practice to divide your dataset into three splits: [train](https://developers.google.com/machine-learning/glossary#training_set), [validation](https://developers.google.com/machine-learning/glossary#validation_set), and [test](https://developers.google.com/machine-learning/glossary#test-set). \n",
    "\n",
    "The IMDB dataset has already been divided into train and test, but it lacks a validation set. Let's create a validation set using an 80:20 split of the training data by using the `validation_split` argument below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOrK-MTYaw3C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 169 files belonging to 2 classes.\n",
      "Using 136 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    '/tmp/classify/train', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='training', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Y33oxOUpYkh"
   },
   "source": [
    "As you can see above, there are 25,000 examples in the training folder, of which you will use 80% (or 20,000) for training. As you will see in a moment, you can train a model by passing a dataset directly to `model.fit`. If you're new to `tf.data`, you can also iterate over the dataset and print out a few examples as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "51wNaPPApk1K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review b'\\n  \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nEe: Fa ko za | | [III Ill (ll\\nse\\ne TelekomSlovanije karin\\nupi 1601540, 1610764.\\nDodatek k Pogodbi o naro\\xc4\\x8dni\\xc5\\xa1kem razmerju za uporabo |D-dodatka SPP\\n\\nm po eli izra p rales ij i me if f\\nelekironskih komunikacijskih storitev\\n\\xc5\\xa0tevilka dodatka: -1894540/D1\\nki ga dogovorita in skleneta Telekom Slovenije, d,d., Cigaletova 15, 1900 Ljubljana (v nadaljevanju: Telekom Slovenije) in naro\\xc4\\x8dnik:\\n\\nDOLENC JANEZ\\n\\npriimek in ime/naziv pravne osebe\\n\\nBOHINJ\\xc4\\x8cEVA ULICA 6, LJUBLJANA\\n\\nnaslov stelnoga bivali\\xc5\\xa1\\xc4\\x8du/sedo\\xc5\\xbe pravne osebo\\n\\n41000 LJUBLJANA\\n\\ngo\\xc5\\xa1ina \\xc5\\xa1lavilka in ime po\\xc5\\xa1la\\n\\n \\n\\n \\n\\n00000000 L] da ne\\ndav\\xc4\\x8dna \\xc5\\xa1tevilka dav\\xc4\\x8dni zavezanec | :\\n\\n\\xe2\\x80\\x94] \\xc5\\xbeenski mo\\xc5\\xa1ki [\\xe2\\x80\\x94] ne \\xc5\\xbeelim podati podatkov o spolu 6.8.1951\\n=a o vie NE a a o sg ee Sareea\\n\\nOsebna Izkaznica\\n\\nvista osebnega dokumenta\"\\nNE\\nzaposlen\"\\n\\n38631466458\\n\\nkontaktni GSM naro\\xc4\\x8dnika\"\\n\" Bodatki, ki so ozna\\xc4\\x8dani z zvezdico, so neobvezni,\\n\\n \\n\\n \\n\\nTabela 1 - Predmet naro\\xc4\\x8dila:\\n\\n \\n\\n \\n\\nZap. |Opis storiteviopreme (Cena Popust Cena skupaj\\n\\n\\xc5\\xa1t. |\\n\\n1 izklju\\xc4\\x8ditev NARO\\xc4\\x8cNINA: | \\'NARO\\xc4\\x8cNINA:\\n\\ni Paket: Osnovni tf, priklju\\xc4\\x8dek (PSTN) 14,00 EUR \\'mesec |: (14,00 EUR /mesec\\nLokacija: BOHINJ\\xc4\\x8cEVA ULICA 6, 1000 LJUBLJANA PREKINITEV: : PREKINITEV:\\nTel. $t.; 915197552 10,95 EUR : 10,95 EUR\\nNaro\\xc4\\x8dni\\xc5\\xa1ki ra\\xc4\\x8dun: 3050258, ULICA PADLIH BORCEV 11, i\\n5220 TOLMIN i i\\n\\nNa\\xc4\\x8din dostave ra\\xc4\\x8duna: Ra\\xc4\\x8dun se po\\xc5\\xa1lje v pisni obliki |\\n| Naslov: ULICA PADLIH BORCEV 11, 5220 TOLMIN : |\\n| | Zeljeni datum izklju\\xc4\\x8ditve: 34.7.2020 \\xe2\\x80\\x94\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n11 |Tel. $1: 015497552 UE ~~ [Del paketa [Del paketa |\\nObjava v imeniku: Tel. \\xc5\\xa1t. objavljena (dovoljeno za i i\\n_.__|komerciaine inraziskovaIne namene) \\xe2\\x80\\x94 \\xe2\\x80\\x94\\xe2\\x80\\x94ooo ee opre oper rregeneee\\xc5\\xa1e\\n[1.1.1 JOmejevanje odhodnih klicev-Omejitev 11 . do RR |\\n\\n \\n\\nVse cene so z DDV.\\n\\nUvodne dolo\\xc4\\x8dbe\\n\\n1. \\xc4\\x8dlen\\n\\nPogodbeni stranki uvodoma ugotavljata, da sta sklenili Pogodbo o naro\\xc4\\x8dni\\xc5\\xa1kem razmerju za uporabo elekironskih komunikacijskih storitev\\nTelekoma Slovenije.\\n\\n2. \\xc4\\x8dlen\\n\\nS iem Dodatkom k pogodbi pogodbeni stranki urejata pravice in obveznosti v zvezi z naro\\xc4\\x8dni\\xc5\\xa1kimi razmorji za posamezne storilvo Telekoma\\nSiovenije, kot je specificirano v Tabeli 1.\\n\\n3. Glen\\n\\nDolo\\xc4\\x8dbe tega Dodatka veljajo za celoten Dodatek, razen kjer je pri posamezni dolo\\xc4\\x8dbi izrecno navedeno, da se nana\\xc5\\xa1a zgolj na dolo\\xc4\\x8deno to\\xc4\\x8dka\\nTabele 1,\\n\\nPrekinitev naro\\xc4\\x8dni\\xc5\\xa1kega razmerja\\n\\n4, Glen (velja za to\\xc4\\x8dke: 1 iz Tabele 1)\\n\\nOb prekinitvi naro\\xc4\\x8dni\\xc5\\xa1kega razmerja mora naro\\xc4\\x8dnik poravnati vse obveznosti iz naro\\xc4\\x8dni\\xc5\\xa1kega razmerja, ki je stvar prekinitve v Tabeli 1, do dneva\\n\\nprekinitve priklju\\xc4\\x8dka/tel. \\xc5\\xa1tevilke.\\nV primeru, da se pa sklenitvi tega Dodatka ugotovi, da ima naro\\xc4\\x8dnik neporavnane pogodbene obveznosti, se naro\\xc4\\x8dnik strinja, da mu Telekom\\n\\n(\\xc5\\xa0i. dodatka: -1601540/D1. ID-stranke: 1610764) Stran 1 od 2\\n\\nTelekom Slovenije, dl.d,, Cigaletova 15, 1000 Ljubljana, tel.: 4386 1 234 10 00, www.telekom.si\\nVa\\xc5\\xbena \\xc5\\xa1tevilka: 1j24524/00, Okro\\xc5\\xbeno sodi\\xc5\\xa1\\xc4\\x8de v Ljubljani, Osnoval kopica: 27 720.664,33 EUR, Mati\\xc4\\x8dna Stevlika 5014018, identifikacijska stevlika za ODY: SISBS11734\\n\\n \\n\\n\\n\\n\\n  \\n\\n\\xc5\\xa0,\\n\\na Te mt\\ne TelekomSiovenije\\nSlovenije le-te zara\\xc4\\x8duna na zadnjem oziroma posebnem ra\\xc4\\x8dunu.\\n\\n5. \\xc4\\x8dlen (velja za to\\xc4\\x8dke: 1 iz Tabele 1)\\n\\nPrekinitev naro\\xc4\\x8dni\\xc5\\xa1kega razmerja bo izvedena najkasneje v roku petih (5) delovnih dni.\\n\\n6. Glen (velja za to\\xc4\\x8dke: 1 iz Tabele 1)\\n\\nNaro\\xc4\\x8dnik se obvezuje, da ho vso opremo last Telakoma Slovenije vrnil Telekomu Slovenije. \\xc4\\x8ce naro\\xc4\\x8dnik v roku petih (5) dni po oddaji Vloge za\\nodpoved naro\\xc4\\x8dni\\xc5\\xa1kega razmerja opreme last Telekoma Slovenije ne vrne, se mu vsa oprema zara\\xc4\\x8duna po Ceniku. Prav tako se naro\\xc4\\x8dniku ob\\n\\nvrnitvi opreme zara\\xc4\\x8duna vsa manjkajo\\xc4\\x8da ih po\\xc5\\xa1kodovana oprema,\\n\\nSklenitev Pogodbe na daljavo ali zunaj poslovnih prostorov\\n\\n7. Glen (velja ra to\\xc4\\x8dke: 1 iz Tabele 1)\\n\\nSoznanjena sem, da ja prodajna ponudba s pogoji za blago/storitev, vklju\\xc4\\x8dno s podatki o zna\\xc4\\x8dilnosti blaga/storitve, ceni, morebitnih dodatnih\\nstro\\xc5\\xa1kih, trajanju in pogoji za prenehanje pogodbe, na vcijo na spletnem mestu www.telekom.si ter na prodajnih mestih Telekoma Slovenije.\\n\\n8. \\xc4\\x8dlen (velja za to\\xc4\\x8dke: 1 Iz Tabele 1)\\n\\nSeznanjerva sem s Pogoji nakupa blaga in storitev (PF), vklju\\xc4\\x8dno s pogoji, roki in postopku za uveljavljanje pravice do odstopa od pogodbe v\\nodstopnem roku 14 dni, ki so na vcijo na www.telekom.si ter na prodajnih mestih Telekoma Slovenije.\\n\\n9. \\xc4\\x8dlen (velja za to\\xc4\\x8dke: 1 iz Tabele 1)\\n\\nizrecno sogla\\xc5\\xa1am, da lahko pri nakupu storitve opravljanje storitve za\\xc4\\x8dne v odslopnem roku 14 dni, kot ga opredeljuje Zakon o varstvu\\npotro\\xc5\\xa1nikov.\\n\\n10. \\xc4\\x8dlen (velja za to\\xc4\\x8dke: 1 iz Tabele 1)\\n\\nizrecno sogla\\xc5\\xa1am, da pri nakupu digitalne vsebine, ki se ne dostavi na ofipljivem nosilcu podatkov, da se opravljanje storitve lahko za\\xc4\\x8dne takoj\\nter da sem seznanjen/a, da s tem nima pravice odstopa od pogodbe v odstopnem roku 14 dni, kot ga opredeljuje Zakon o varstvu potro\\xc5\\xa1nikov,\\n\\nKon\\xc4\\x8dne dolo\\xc4\\x8dbe\\n\\n41. Glen (velja za io\\xc4\\x8dko: 1 iz Yabele 1)\\n\\nTa dodatek je napisan v 2 (dveh) enakih izvodih od katerih vsaka pogodbena stranka prejme po en izvod in pri\\xc4\\x8dne veljati z dnem, ko jo\\npodpi\\xc5\\xa1eta obe pogodbeni siranki.\\n\\n   \\n\\nPodpigal; Telekom Slovanija, d.d\\nKraj podplsa: LJUBLJANA\\nPo\\xc4\\x8dpisano dne: 2020-07-28, 17:88:33\\nRazlog podpisa: ePero slektconski podpis\\n\\n      \\n   \\n\\n \\n\\n \\n\\nPotrjujem, da sem prever] vse podalke, ki so navedeni v iem dodatku, in jam\\xc4\\x8dim, da so to\\xc4\\x8dni in resni\\xc4\\x8dni. U \\xe2\\x80\\x9d GO 3.1/0002.5 (17. 7. 2079\\n\\nKERSMANC ZIGA H 2742 LJUBLJANA\\n\\n| izpis imena zaposlenega \\xc5\\xa1iira prodajalca \\xc5\\xa1ilra prodajnega mesta kraj\\n\\n29.7.2020.\\n\\ndatum\\n\\n(\\xc5\\xa0i. dodatka; -1601540/D1, 1D-stranke: 1610764) Siran 2 od 2\\n\\nTelekorn Slovenije, d.d., Cigaletova 15, 1000 Ljubljana, tel,: -388 1 234 10 00, www.telekom.si\\nWo\\xc5\\xbena \\xc5\\xa1tevlika: 1j/P0524/00, Okro\\xc5\\xbeno sodi\\xc5\\xa1\\xc4\\x8de v Liubijani, Osnovni kapital: 272,720.6b,53 kUR, Mati\\xc4\\x8dna \\xc5\\xa1tovlika 5014619, slentifikacijska \\xc5\\xa1tevilka za DOV: 98511734\\n\\n \\n\\n \\n\\n\\n\\n\\n'\n",
      "Label 1\n",
      "Review b'\\nTelekom Slovenije AL\\n\\n09102020031104468\\n\\nVloga za zamenjavo kartice SIM 20351380 43393.\\nID-obrazca SPP\\n\\n \\n\\nNaro\\xc4\\x8dnik mobilne telefonske \\xc5\\xa1tevilke/uporabnik Mobi:\\nENERGETIKA LJUBLJANA, D.O.O.\\n\\nnaziv/priimek in ime\\nVEROV\\xc5\\xa0KOVA ULICA 62\\n\\nnaslov\\n\\n1000 LJUBLJANA 99\\n\\n\\xc5\\xa1tevilka in ime po\\xc5\\xa1te id odobritve\\n\\n \\n\\n \\n\\n \\n\\nkraj rojstva za fizi\\xc4\\x8dne osebe\\n051357435 12.03.2020 15:00:00\\n\\nmobilna telefonska \\xc5\\xa1tevilka / telefonska \\xc5\\xa1tevilka Mobi datum izvedbe zamenjave kartice SIM\\n\\n030430503610 170333382892\\n\\nstara kartica SIM / SIM Mobi nava kartica SIM / SIM Mobi\\n\\nRazlog za zamenjavo kartice SIM:\\nnakup novega aparata\\n\\n[].\\' blokirana SIM (napa\\xc4\\x8den vnos PIN/PUK)\\n\\n[]  kraja/izguba SIM\\n\\nPrenos podatkov s stare kartice SIM / SIM Mobi na novo:\\nda CI ne\\n\\nIzjava naro\\xc4\\x8dnika:\\n\". S to vlogo zahtevam spremembo Pogodbe o sklenitvi naro\\xc4\\x8dni\\xc5\\xa1kega razmerja v delu, ki dolo\\xc4\\x8da serijsko \\xc5\\xa1tevilko kartice SIM.\\n\\xc2\\xbb. S podpisom potrjujem, da sem seznanjen/a s Splo\\xc5\\xa1nimi pogoji uporabe elektronskih komunikacijskih storitev dru\\xc5\\xbebe Telekom Slovenije, d.d. ter da prevzemam\\n\\nvse pravice in odgovornosti, ki izhajajo iz njih,\\n\\n\\xc2\\xbb. S podpisom sogla\\xc5\\xa1am, da izvedena pozitivna re\\xc5\\xa1itev te vloge predstavlja veljavno spremembo Pogodbe o sklenitvi naro\\xc4\\x8dni\\xc5\\xa1kega razmerja v zgoraj navedenem\\nobsegu.\\n\\n\". S podpisom potrjujem prevzem kartice SIM.\\n\\n\\xc2\\xbb Podatki, ki sem jih navedel/a, so to\\xc4\\x8dni in resni\\xc4\\x8dni,\\n\\nV primeru sklenitve Pogodbe na daljavo ali zunaj poslovnih prostorov, naro\\xc4\\x8dnik potrjuje:\\n\\n* da je seznanjen, da je prodajna ponudba s pogoji za blago/storitev, vklju\\xc4\\x8dno s podatki o zna\\xc4\\x8dilnosti blaga/storitve, ceni, morebitnih dodatnih stro\\xc5\\xa1kih, trajanju in\\npogoji za prenehanje pogodbe, na voljo na spletnem mestu www.telekom.si ter na prodajnih mestih Telekoma Slovenije;\\n\\n\". da je seznanjen s Pogoji nakupa blaga in storitev (PP), vklju\\xc4\\x8dno s pogoji, roki in postopku za uveljavljanje pravice do odstopa od pogodbe v odstopnem roku 14\\ndni, ki so na voljo na www.telekom.si ter na prodajnih mestih Telekoma Slovenije;\\n\\n\\xc2\\xbb. da pri nakupu storitve izrecno sogla\\xc5\\xa1a, da se lahko opravljanje storitve za\\xc4\\x8dne v odstopnem roku 14 dni, kot ga opredeljuje Zakon o varstvu potro\\xc5\\xa1nikov.\\n\\nPomembna obvestila:\\n\\xc2\\xbb. Sprememba bo urejena najkasneje v petih (5) delovnih dneh od prejema pravilno izpolnjene vloge.\\n\\xc2\\xbb. Menjava kartice SIM se zara\\xc4\\x8duna po veljavnem ceniku.\\n\\nIzjava uporabnika Mobi:\\n\\n* S podpisom potrjujem prevzem nove kartice SIM Mobi.\\n\\n\\xc2\\xbb. S podpisom potrjujem, da sem seznanjen/a s Pogoji poslovanja in uporabe storitev predpla\\xc4\\x8dni\\xc5\\xa1ke telefonije Mobi v omre\\xc5\\xbeju dru\\xc5\\xbebe Telekom Slovenije, d.d. (v\\nnadaljevanju Telekom Slovenije).\\n\\nPriloga:\\n\\n\". Kopija certifikata Mobi ali kopija kartice SIM ali kopija izpisa kod PIN in PUK.\\n\\nIzpolnjeno vlogo oddajte v Telekomovem centru ali jo po\\xc5\\xa1ljete na naslov Telekom Slovenije. d.d., Naro\\xc4\\x8dni\\xc5\\xa1ka razmerja, 1546 Ljubljana, po faksu\\nna \\xc5\\xa1tevilko 01 47 22 306 ali na e-naslov info@ielekom.si, 5\\n\\nLJUBLJANA 11.03.2020 - PO POOBLASTIL tt\\n\\nkraj datum izpis priimka in imena zastopnika pravne\\nosebe uporabnika/Mobi\\n\\n  \\n    \\n \\n \\n\\n \\n\\n \\n\\n    \\n\\n   \\n\\nIzpolni Telekom Slovenije, d.d., oz. poobla\\xc5\\xa1\\xc4\\x8den posrednik\\n\\nKOBAL ANKA 2401\\nizpis imena zaposlenega \\xc5\\xa1ifra prodajnega mesta\\n\\nGO 3.2/066.11 (17. 1.2019)\\n\\n \\n \\n  \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nStran 1 od 1\\n\\nTelekom Slovenije, d.d., Cigaletova 15, 1000 Ljubljana, tel.: 4486 1 234 10 00, www.telekom.si\\nVlo\\xc5\\xbena \\xc5\\xa1tevlika: 1/24624/00, Okro\\xc5\\xbeno sodi\\xc5\\xa1\\xc4\\x8de v Ljubljani, Osnovni kapital: 272.720.664.33 EUR. Mati\\xc4\\x8dna \\xc5\\xa1tevilka 5014018, Identifikacijska \\xc5\\xa1tevlika za DDV: SI98511734\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "Label 1\n",
      "Review b'\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n09102020072801118\\n. . .. 1587281 1022115\\nPotrdilo o izdaji opreme ID-naro\\xc4\\x8dila SPP\\nPodatki o naro\\xc4\\x8dniku/uporabniku:\\nNADA \\xc5\\xa0MID\\npriimek in ime/naziv pravne osebe\\nzastopnik pravne osebe\\nSTRESOVA ULICA 4A\\nnaslov stalnega bivali\\xc5\\xa1\\xc4\\x8da/sede\\xc5\\xbe pravne osebe\\n5222 KOBARID\\npo\\xc5\\xa1tna \\xc5\\xa1tevilka in ime po\\xc5\\xa1te\\n37415506 Osebna Izkaznica\\ndav\\xc4\\x8dna \\xc5\\xa1tevilka \\xc5\\xa1tevilka osebnega dokumenta\" vrsta osebnega dokumenta\"\\n38651312980\\nkontaktna tel. \\xc5\\xa1t.\" kontaktna oseba\" kontaktni elektronski naslov\"\\n\\xc5\\xa1tevilka dodatka/pogodbe\\n\" Podatki, ki so ozna\\xc4\\x8deni z zvezdico, so neobvezni.\\nZap. |aktivnost parametri opreme koli\\xc4\\x8dina |Cene Cena za stranko\\n\\xc5\\xa1t.  jrazlog\\n1 prevzem Doro 6050 sivo-bela , 1 Blago: 75,00 EUR (Blago: 24,00 EUR\\nserijska \\xc5\\xa1tevilka: 351757085882645 ,\\ntelefonska \\xc5\\xa1tevilka: 053885190 , uporabni\\xc5\\xa1ko ime: nsmid11\\nOpombe: .\\n\\nPrevzem opreme\\n1. \\xc4\\x8dlen\\n\\nSpodaj podpisani naro\\xc4\\x8dnik potrjujem prevzem opreme.\\n\\n2. \\xc4\\x8dlen\\n\\nPotrjujem, da sem seznanjen/a, da se mi v primeru izgube, po\\xc5\\xa1kodbe ali odtujitve opreme last Telekoma Slovenije, d.d., le-ta zara\\xc4\\x8duna po\\nveljavnem Ceniku.\\n\\n3. \\xc4\\x8dlen\\n\\nNaro\\xc4\\x8dnik je seznanjen, da mora opremo last Telekoma Slovenije, d.d., vrniti v tak\\xc5\\xa1nem stanju in koli\\xc4\\x8dini, v kakr\\xc5\\xa1nem mu je bila izro\\xc4\\x8dena.\\n\\nPodpisal: Telekom Slovenije, d.d\\nKraj podpisa: LJUBLJANA\\n\\nPodpisano dne: 2020-07-28, 00:36:48\\nRaziog podpisa: sPero elektronski podpis\\n\\n \\n\\nTelekom Slovenije d.d., po pooblastilu uprave\\n\\n)\\nSina Ma\\n\\n   \\n\\npodpis naro\\xc4\\x8dnika/uporabnika\\n\\n \\n\\n \\n\\n \\n\\n \\n\\nPotrjujem, da sem preveril vse podatke, ki so navedeni v tej pogodbi, in jam\\xc4\\x8dim, da so to\\xc4\\x8dni in resni\\xc4\\x8dni. GO 3.1/0016.3 (17. 7. 2019\\nZIBELNIK ANDREJ 2396 LJUBLJANA 28.7.2020\\nizpis imena zaposlenega \\xc5\\xa1ifra prodajalca \\xc5\\xa1ifra prodajnega mesta kraj datum\\nStran 1 od 1\\n\\nTelekom Slovenije, d.d., Cigaletova 15, 1000 Ljubljana, tel.: \\xc2\\xa3386 1 234 10 00, www.telekom.si\\n\\nVlo\\xc5\\xbena \\xc5\\xa1tevilka: 1/24624/00, Okro\\xc5\\xbeno sodi\\xc5\\xa1\\xc4\\x8de v Ljubljani, Osnovni kapital: 272,720.664,33 EUR, Mati\\xc4\\x8dna \\xc5\\xa1tevilka 5014018, Identifikacijska \\xc5\\xa1tevlika za DDV: S198511734\\n\\n \\n\\n\\n\\n\\n'\n",
      "Label 1\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(\"Review\", text_batch.numpy()[i])\n",
    "    print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWq1SUIrp1a-"
   },
   "source": [
    "Notice the reviews contain raw text (with punctuation and occasional HTML tags like `<br/>`). You will show how to handle these in the following section. \n",
    "\n",
    "The labels are 0 or 1. To see which of these correspond to positive and negative movie reviews, you can check the `class_names` property on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlICTG8spyO2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to 391.60\n",
      "Label 1 corresponds to 398\n"
     ]
    }
   ],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbdO39vYqdJr"
   },
   "source": [
    "Next, you will create a validation and test dataset. You will use the remaining 5,000 reviews from the training set for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzxazN8Hq1pF"
   },
   "source": [
    "Note:  When using the `validation_split` and `subset` arguments, make sure to either specify a random seed, or to pass `shuffle=False`, so that the validation and training splits have no overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JsMwwhOoqjKF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 171 files belonging to 2 classes.\n",
      "Using 34 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory('/tmp/classify/train', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.2, \n",
    "    subset='validation', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdSr0Nt3q_ns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    502\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1503\u001b[0m           \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1504\u001b[0;31m           (dtype.name, value.dtype.name, value))\n\u001b[0m\u001b[1;32m   1505\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor 'args_0:0' shape=() dtype=float32>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-79f37f44d7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'/tmp/classify/test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     batch_size=batch_size)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/text_dataset.py\u001b[0m in \u001b[0;36mtext_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, batch_size, max_length, shuffle, seed, validation_split, subset, follow_links)\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0mlabel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m       max_length=max_length)\n\u001b[0m\u001b[1;32m    162\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;31m# Shuffle locally at each iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/text_dataset.py\u001b[0m in \u001b[0;36mpaths_and_labels_to_dataset\u001b[0;34m(file_paths, labels, label_mode, num_classes, max_length)\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0mpath_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m   string_ds = path_ds.map(\n\u001b[0;32m--> 179\u001b[0;31m       lambda x: path_to_string_content(x, max_length))\n\u001b[0m\u001b[1;32m    180\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlabel_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mlabel_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \"\"\"\n\u001b[1;32m   1702\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4102\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4103\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4104\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4105\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3425\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3427\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3429\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3036\u001b[0m     \"\"\"\n\u001b[1;32m   3037\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3038\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3039\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3040\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3003\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3004\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3006\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3332\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3333\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3334\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3186\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3187\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3188\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3190\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3418\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3419\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3420\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3421\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3353\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3355\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3356\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3357\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/text_dataset.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0mpath_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m   string_ds = path_ds.map(\n\u001b[0;32m--> 179\u001b[0;31m       lambda x: path_to_string_content(x, max_length))\n\u001b[0m\u001b[1;32m    180\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlabel_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mlabel_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/text_dataset.py\u001b[0m in \u001b[0;36mpath_to_string_content\u001b[0;34m(path, max_length)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpath_to_string_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m   \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmax_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m--> 576\u001b[0;31m         \"ReadFile\", filename=filename, name=name)\n\u001b[0m\u001b[1;32m    577\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    524\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_INVALID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             raise TypeError(\"%s expected type of %s.\" %\n\u001b[0;32m--> 526\u001b[0;31m                             (prefix, dtypes.as_dtype(input_arg.type).name))\n\u001b[0m\u001b[1;32m    527\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;31m# Update the maps with the default, if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string."
     ]
    }
   ],
   "source": [
    "raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    '/tmp/classify/test', \n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kDA_Lu2PoGyP"
   },
   "source": [
    "Note: The Preprocessing APIs used in the following section are experimental in TensorFlow 2.3 and subject to change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJmTiO0IYAjm"
   },
   "source": [
    "### Prepare the dataset for training\n",
    "\n",
    "Next, you will standardize, tokenize, and vectorize the data using the helpful `preprocessing.TextVectorization` layer. \n",
    "\n",
    "Standardization refers to preprocessing the text, typically to remove punctuation or HTML elements to simplify the dataset. Tokenization refers to splitting strings into tokens (for example, splitting a sentence into individual words, by splitting on whitespace). Vectorization refers to converting tokens into numbers so they can be fed into a neural network. All of these tasks can be accomplished with this layer.\n",
    "\n",
    "As you saw above, the reviews contain various HTML tags like `<br />`. These tags will not be removed by the default standardizer in the `TextVectorization` layer (which converts text to lowecase and strips punctuation by default, but doesn't strip HTML). You will write a custom standardization function to remove the HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZVcHl-SLrH-u"
   },
   "source": [
    "Note: to prevent [train/test skew](https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew) (also know as train/serving skew), it is important to preprocess the data identically at train and test time. To facilitate this, the `TextVectorization` layer can be included directly inside your model, as shown later in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDRI_s_tX1Hk"
   },
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2d3Aw8dsUux"
   },
   "source": [
    "Next, you will create a `TextVectorization` layer. you will use this layer to standardize, tokenize, and vectorize our data. You set the `output_mode` to `int` to create unique integer indices for each token.\n",
    "\n",
    "Note that you're using the default split function, and the custom standardization function you defined above. You'll also define some constants for the model, like an explicit maximum `sequence_length`, which will cause the layer to pad or truncate sequences to exactly `sequence_length` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-c76RvSzsMnX"
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "sequence_length = 250\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlFOpfF6scT6"
   },
   "source": [
    "Next, you will call `adapt` to fit the state of the preprocessing layer to the dataset. This will cause the model to build an index of strings to integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAhdjK7AtroA"
   },
   "source": [
    "Note: it's important to only use your training data when calling adapt (using the test set would leak information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GH4_2ZGJsa_X"
   },
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call adapt\n",
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHQVEFzNt-K_"
   },
   "source": [
    "Let's create a function to see the result of using this layer to preprocess some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCIg_T50wOCU"
   },
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XULcm6B3xQIO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review tf.Tensor(b'\\nx IA\\nBe TelekomSlovenije\\n\\ne 09102020080302163\\n\\n    \\n\\n \\n\\n \\n\\nNaro\\xc4\\x8dilo doc storitev, Vloga za s j 20972633. 17185\\nvo ev j : . . ID-obrazca SPP\\n\\nnaro\\xc4\\x8dni\\xc5\\xa1ke rja v delu, ki dolo\\n\\nPodatki o naro\\xc4\\x8dniku:\\n\\nUL MF 1000 LJUBLJANA\\n\\nnaziv/priimek in ime \\xc5\\xa1tevilka in ime po\\xc5\\xa1te\\n\\nVRAZOV TRG 2 051231627\\n\\nnaslov mobilna telefonska \\xc5\\xa1tevilka id odobritve\\n\\nNaro\\xc4\\x8dam [| vklop izklop naslednjih storitev\\n- Dodatni zakup 20 GB\\n\\nOpombe: IZKLOP Z 31.08.2020\\n\\nDGPS:\\n\\n \\n\\npriimek in ime uporabnika (za obve\\xc5\\xa1\\xc4\\x8danje s strani GIS-a): e-po\\xc5\\xa1tni naslov ali tel. \\xc5\\xa1t. (GIS):\\n\\nAPN:\\nLTE/4G:\\n\\n \\n\\n \\n\\nLTE profil\\nSeznanjen sem z dolo\\xc4\\x8dili Zakona o varstvu osebnih podatkov. Izpis potrebujem za lastne, naro\\xc4\\x8dni\\xc5\\xa1ke potrebe.\\nPo oddaji Telekom Slovenije ne prevzema odgovornosti za nadaljnje varovanje podatkov, ki so na seznamu.\\n\\nIZPOLNI TC\\n\\nDodeljena faks. \\xc5\\xa1tevilka: Dodeljena data \\xc5\\xa1tevilka:\\n\\n \\n\\n \\n\\n \\n\\nIzjave in pomembna obvestila:\\n\\n+ Prodajna ponudba s pogoji za posamezno dodatno storitev je na voljo na spletni strani www.telekom.si ter na prodajnih mestih Telekoma Slovenije.\\n\\n* s to vlogo zahtevam spremembo Pogodbe o sklenitvi naro\\xc4\\x8dni\\xc5\\xa1kega razmerja v delu, ki dolo\\xc4\\x8da dodatne mobilne storitve.\\n\\nS podpisom potrjujem, da sem seznanjen/a s Splo\\xc5\\xa1nimi pogoji uporabe elektronskih komunikacijskih storitev Telekoma Slovenije, d.d., (v nadaljevanju: SPU) ter da prevzemam vse pravice in odgovomosti, ki\\nizhajajo iz SPU.\\n\\nS podpisom sogla\\xc5\\xa1am, da izvedena pozitivna re\\xc5\\xa1itev te vloge predstavlja veljavno spremembo Pogodbe o sklenitvi naro\\xc4\\x8dni\\xc5\\xa1kega razmerja v zgoraj navedenem obsegu.\\n\\nDodatne storitve bodo vklju\\xc4\\x8dene najkasneje v petih (5) delovnih dneh od prejema pravilno izpolnjene vloge oziroma v skladu s prodajno ponudbo za posamezno dodatno storitev\\n\\nDodatne storitve se zara\\xc4\\x8dunavajo v skladu z veljavnim cenikom.\\n\\nNaro\\xc4\\x8dnik je seznanjen z morebitnimi stro\\xc5\\xa1ki zaradi konfere\\xc4\\x8dnih klicev (MPTY) in klicev na \\xc4\\x8dakanju (HOLD) med gostovanjem v tujini. Obra\\xc4\\x8dunajo se v skladu z veljavnim cenikom.\\n\\nNaro\\xc4\\x8dnik je seznanjen s tveganjem visokega stro\\xc5\\xa1ka ob gostovanju v tujem omre\\xc5\\xbeju v kolikor pride do zlorabe mobilne naprave. Nasveti uporabnikom mobilnih komunikacijskih naprav za za\\xc5\\xa1\\xc4\\x8dito pred dragimi\\n\\nklici so objavljeni na www.telekom.si\\n\\nOb sklenitvi naro\\xc4\\x8dni\\xc5\\xa1kega razmerja, tekom trajanja in/ali ob prekinitvi le-tega, lahko naro\\xc4\\x8dniku nastanejo dodatni stro\\xc5\\xa1ki: npr. popla\\xc4\\x8dilo preostalih pogodbenih obveznosti; ali pla\\xc4\\x8dilo storitev oz. administrativnih\\nstro\\xc5\\xa1kov, kot so opredeljeni v ceniku \\xc2\\xbbSplo\\xc5\\xa1ne storitve\\xc2\\xab oz. ostalih cenikih, ki so na voljo na spletnih in prodajnih mestih Telekoma Slovenije. Telekom Slovenije naro\\xc4\\x8dniku predlaga, da se z vsebino teh\\ndokumentov seznani.\\n\\nV primeru sklenitve Pogodbe na daljavo ali zunaj poslovnih prostorov, naro\\xc4\\x8dnik potrjuje:\\n\\nda je seznanjen, da je prodajna ponudba s pogoji za blago/storitev, vklju\\xc4\\x8dno s podatki o zna\\xc4\\x8dilnosti blaga/storitve, ceni, morebitnih dodatnih stro\\xc5\\xa1kih, trajanju in pogoji za prenehanje pogodbe na voljo na\\nspletnem mestu www.telekom.si ter na prodajnih mestih Telekoma Slovenije;\\n\\nda je seznanjen s Pogoji nakupa blaga in storitev (PP), vklju\\xc4\\x8dno s pogoji, roki in postopku za uveljavljanje pravice do odstopa od pogodbe v odstopnem roku 14 dni, ki so na voljo na www.telekom.si ter na\\nprodajnih mestih Telekoma Slovenije;\\n\\nda pri nakupu storitve izrecno sogla\\xc5\\xa1a, da se lahko opravljanje storitve za\\xc4\\x8dne v odstopnem roku 14 dni, kot ga opredeljuje Zakon o varstvu potro\\xc5\\xa1nikov;\\n\\nda pri nakupu digitalne vsebine, ki se ne dostavi na otipljivem nosilcu podatkov izrecno sogla\\xc5\\xa1a, da se opravljanje storitve lahko za\\xc4\\x8dne takoj ter daje seznanjen, da stem nima pravice odstopa od pogodbe v\\nodstopnem roku 14 dni, kot ga opredeljuje Zakon o varstvu potro\\xc5\\xa1nikov.\\n\\n   \\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nIzpolnjeno vlogo oddajte v Tel li jo po\\xc5\\xa1ljete na naslov Te Slovenije, d.d., Naro\\xc4\\x8d razmerja, 1546 Lju la, po faksu\\nna \\xc5\\xa1tevilko 01 47 ali na e-naslov in 1\\nDigitally signed by EMIL\\n\\nEMIL HUDOMALJ\\n\\nHUDOMALJ Date: 2020.08.03 \\xc5\\xbeig\\nLJUBLJANA 03.08.2020 - 10:04:48 0200: naro\\xc4\\x8dnika\\nraj datum izpis priimka in imena zastopnika pravne osebe podpis naro\\xc4\\x8dnika/zastopnika pravne osebe\\nIzpolni Telekom Slovenije, d.d., oz. poobla\\xc5\\xa1\\xc4\\x8deni prodajalec GO 3.2/063.101 (5. 9. 2019)\\nKOBAL ANKA 2401\\nizpis imena zaposlenega \\xc5\\xa1ifra prodajnega mesta\\n\\nStran 1 od 1\\n\\nTelekom Slovenije, d.d., Cigaletova 15, 1000 Ljubljana, tel.: +386 1 234 10 00, www.telekom.si\\n\\nVlo\\xc5\\xbena \\xc5\\xa1tevilka: 1/248624/00, Okro\\xc5\\xbeno sodi\\xc5\\xa1\\xc4\\x8de v Ljubljani, Osnovni kapital: 272.720.664,33 EUR, Mati\\xc4\\x8dna \\xc5\\xa1tevilka 5014018, Identifikacijska \\xc5\\xa1tevilka za DDV: SI98511734\\n\\n \\n\\n \\n\\n\\n\\n\\n', shape=(), dtype=string)\n",
      "Label 398\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vectorize_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3f3fb1182f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Review\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_train_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Vectorized review\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_review\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorize_text' is not defined"
     ]
    }
   ],
   "source": [
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6u5EX0hxyNZT"
   },
   "source": [
    "As you can see above, each token has been replaced by an integer. You can lookup the token (string) that each integer corresponds to by calling `.get_vocabulary()` on the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kRq9hTQzhVhW"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorize_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fd1767ddfcad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1287 ---> \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1287\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" 313 ---> \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m313\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Vocabulary size: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vectorize_layer' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
    "print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
    "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XD2H6utRydGv"
   },
   "source": [
    "You are nearly ready to train your model. As a final preprocessing step, you will apply the TextVectorization layer you created earlier to the train, validation, and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zhmpeViI1iG"
   },
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YsVQyPMizjuO"
   },
   "source": [
    "### Configure the dataset for performance\n",
    "\n",
    "These are two important methods you should use when loading data to make sure that I/O does not become blocking.\n",
    "\n",
    "`.cache()` keeps data in memory after it's loaded off disk. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache, which is more efficient to read than many small files.\n",
    "\n",
    "`.prefetch()` overlaps data preprocessing and model execution while training. \n",
    "\n",
    "You can learn more about both methods, as well as how to cache data to disk in the [data performance guide](https://www.tensorflow.org/guide/data_performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMcs_H7izm5m"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLC02j2g-llC"
   },
   "source": [
    "### Create the model\n",
    "\n",
    "It's time to create our neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkQP6in8yUBR"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpKOoWgu-llD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160016    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features + 1, embedding_dim),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PbKQ6mucuKL"
   },
   "source": [
    "The layers are stacked sequentially to build the classifier:\n",
    "\n",
    "1. The first layer is an `Embedding` layer. This layer takes the integer-encoded reviews and looks up an embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: `(batch, sequence, embedding)`.  To learn more about embeddings, see the [word embedding tutorial](../text/word_embeddings.ipynb).\n",
    "2. Next, a `GlobalAveragePooling1D` layer returns a fixed-length output vector for each example by averaging over the sequence dimension. This allows the model to handle input of variable length, in the simplest way possible.\n",
    "3. This fixed-length output vector is piped through a fully-connected (`Dense`) layer with 16 hidden units. \n",
    "4. The last layer is densely connected with a single output node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L4EqVWg4-llM"
   },
   "source": [
    "### Loss function and optimizer\n",
    "\n",
    "A model needs a loss function and an optimizer for training. Since this is a binary classification problem and the model outputs a probability (a single-unit layer with a sigmoid activation), you'll use `losses.BinaryCrossentropy` loss function.\n",
    "\n",
    "Now, configure the model to use an optimizer and a loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mr0GP-cQ-llN"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=losses.BinaryCrossentropy(from_logits=True), optimizer='adam', metrics=tf.metrics.BinaryAccuracy(threshold=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35jv_fzP-llU"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "You will train the model by passing the `dataset` object to the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXSGrjWZ-llW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.6829 - binary_accuracy: 0.6159 - val_loss: 0.6146 - val_binary_accuracy: 0.7722\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.5797 - binary_accuracy: 0.7817 - val_loss: 0.4973 - val_binary_accuracy: 0.8210\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.4653 - binary_accuracy: 0.8363 - val_loss: 0.4195 - val_binary_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.3904 - binary_accuracy: 0.8617 - val_loss: 0.3736 - val_binary_accuracy: 0.8606\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3439 - binary_accuracy: 0.8738 - val_loss: 0.3450 - val_binary_accuracy: 0.8680\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3108 - binary_accuracy: 0.8878 - val_loss: 0.3260 - val_binary_accuracy: 0.8728\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2856 - binary_accuracy: 0.8962 - val_loss: 0.3126 - val_binary_accuracy: 0.8730\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2664 - binary_accuracy: 0.9034 - val_loss: 0.3032 - val_binary_accuracy: 0.8754\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2498 - binary_accuracy: 0.9098 - val_loss: 0.2964 - val_binary_accuracy: 0.8764\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2343 - binary_accuracy: 0.9161 - val_loss: 0.2920 - val_binary_accuracy: 0.8784\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EEGuDVuzb5r"
   },
   "source": [
    "### Evaluate the model\n",
    "\n",
    "Let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOMKywn4zReN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3101 - binary_accuracy: 0.8744\n",
      "Loss:  0.31010234355926514\n",
      "Accuracy:  0.8743600249290466\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1iEXVTR0Z2t"
   },
   "source": [
    "This fairly naive approach achieves an accuracy of about 86%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldbQqCw2Xc1W"
   },
   "source": [
    "### Create a plot of accuracy and loss over time\n",
    "\n",
    "`model.fit()` returns a `History` object that contains a dictionary with everything that happened during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YcvZsdvWfDf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_CH32qJXruI"
   },
   "source": [
    "There are four entries: one for each monitored metric during training and validation. You can use these to plot the training and validation loss for comparison, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SEMeQ5YXs8z"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3PJemLPXwz_"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFFyCuJoXy7r"
   },
   "source": [
    "In this plot, the dots represent the training loss and accuracy, and the solid lines are the validation loss and accuracy.\n",
    "\n",
    "Notice the training loss *decreases* with each epoch and the training accuracy *increases* with each epoch. This is expected when using a gradient descent optimization—it should minimize the desired quantity on every iteration.\n",
    "\n",
    "This isn't the case for the validation loss and accuracy—they seem to peak before the training accuracy. This is an example of overfitting: the model performs better on the training data than it does on data it has never seen before. After this point, the model over-optimizes and learns representations *specific* to the training data that do not *generalize* to test data.\n",
    "\n",
    "For this particular case, you could prevent overfitting by simply stopping the training when the validation accuracy is no longer increasing. One way to do so is to use the [EarlyStopping callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping?version=nightly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-to23J3Vy5d3"
   },
   "source": [
    "## Export the model\n",
    "\n",
    "In the code above, you applied the `TextVectorization` layer to the dataset before feeding text to the model. If you want to make your model capable of processing raw strings (for example, to simplify deploying it), you can include the `TextVectorization` layer inside your model. To do so, you can create a new model using the weights you just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWXsMvryuZuq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3149 - accuracy: 0.8702\n",
      "0.8743600249290466\n"
     ]
    }
   ],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  model,\n",
    "  layers.Activation('sigmoid')\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Test it with `raw_test_ds`, which yields raw strings\n",
    "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MaxlpFWpzR6c"
   },
   "source": [
    "Including the text preprocessing logic inside your model enables you to export a model for production that simplifies deployment, and reduces the potential for [train/test skew](https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew).\n",
    "\n",
    "There is a performance difference to keep in mind when choosing where to apply your TextVectorization layer. Using it outside of your model enables you to do asynchronous CPU processing and buffering of your data when training on GPU. So, if you're training your model on the GPU, you probably want to go with this option to get the best performance while developing your model, then switch to including the TextVectorization layer inside your model when you're ready to prepare for deployment.\n",
    "\n",
    "Visit this [tutorial](https://www.tensorflow.org/tutorials/keras/save_and_load) to learn more about saving models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSSuci_6nCEG"
   },
   "source": [
    "## Exercise: multiclass classification on Stack Overflow questions\n",
    "\n",
    "This tutorial showed how to train a binary classifier from scratch on the IMDB dataset. As an exercise, you can modify this notebook to train a multiclass classifier to predict the tag of a programming question on [Stack Overflow](http://stackoverflow.com/).\n",
    "\n",
    "We have prepared a [dataset](http://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz) for you to use containing the body of several thousand programming questions (for example, \"How can sort a dictionary by value in Python?\") posted to Stack Overflow. Each of these is labeled with exactly one tag (either Python, CSharp, JavaScript, or Java). Your task is to take a question as input, and predict the appropriate tag, in this case, Python. \n",
    "\n",
    "The dataset you will work with contains 8,000 questions extracted from the much larger public Stack Overflow dataset on [BigQuery](https://console.cloud.google.com/marketplace/details/stack-exchange/stack-overflow), which contains more than 17 million posts.\n",
    "\n",
    "After downloading the dataset, you will find it has a similar directory structure to the IMDB dataset you worked with previously:\n",
    "\n",
    "```\n",
    "train/\n",
    "...python/\n",
    "......0.txt\n",
    "......1.txt\n",
    "...javascript/\n",
    "......0.txt\n",
    "......1.txt\n",
    "...csharp/\n",
    "......0.txt\n",
    "......1.txt\n",
    "...java/\n",
    "......0.txt\n",
    "......1.txt\n",
    "```\n",
    "\n",
    "Note: to increase the difficulty of the classification problem, we have replaced any occurences of the words Python, CSharp, JavaScript, or Java in the programming questions with the word *blank* (as many questions contain the language they're about). \n",
    "\n",
    "To complete this exercise, you should modify this notebook to work with the Stack Overflow dataset by making the following modifications:\n",
    "\n",
    "1. At the top of your notebook, update the code that downloads the IMDB dataset with code to download the [Stack Overflow dataset](http://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz) we have prepreared. As the Stack Overflow dataset has a similar directory structure, you will not need to make many modifications. \n",
    "\n",
    "1. Modify the last layer of your model to read `Dense(4)`, as there are now four output classes.\n",
    "\n",
    "1. When you compile your model, change the loss to [SparseCategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy?version=nightly). This is the correct loss function to use for a multiclass classification problem, when the labels for each class are integers (in our case, they can be 0, *1*, *2*, or *3*).\n",
    "\n",
    "1. Once these changes are complete, you will be able to train a multiclass classifier. \n",
    "\n",
    "If you get stuck, you can find a solution [here](https://github.com/tensorflow/examples/blob/master/community/text_classification_solution.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0T5SIwSm7uc"
   },
   "source": [
    "## Learning more\n",
    "\n",
    "This tutorial introduced text classification from scratch. To learn more about the text classification workflow in general, we recommend reading [this guide](https://developers.google.com/machine-learning/guides/text-classification/) from Google Developers.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
